{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa549812",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fb9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dateutil.parser\n",
    "from statistics import mean\n",
    "import math\n",
    "import csv\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "from tkinter import * \n",
    "from tkinter.ttk import *\n",
    "from tkinter.filedialog import askopenfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a887d8f",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944ea8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from : Huseyn Mammadli , https://stackoverflow.com/questions/19944712/browse-for-file-path-in-python/66699008#66699008\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"KPIs Comparators\")\n",
    "root.geometry('700x600')\n",
    "path = \"\"\n",
    "\n",
    "def open_file(): \n",
    "    file = askopenfile(mode ='r', filetypes =[('csv Files', '*.csv')])\n",
    "    if file is not None:\n",
    "        global path\n",
    "        path = file.name\n",
    "        root.destroy()\n",
    "    \n",
    "     \n",
    "\n",
    "btn = Button(root, text ='Browse File Directory', command =lambda:open_file())\n",
    "btn.pack(side = TOP, pady = 10) \n",
    "\n",
    "mainloop() \n",
    "folder_path = os.path.dirname(path)\n",
    "final_csv_path = folder_path + \"/Benchmarked_KPIs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ee801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce940719",
   "metadata": {},
   "source": [
    "# Cell Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d0c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassi\\AppData\\Local\\Temp/ipykernel_14600/593265475.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  raw_KPIs= np.genfromtxt(path, delimiter = ',', skip_header = 1, autostrip = True, dtype = np.str)\n",
      "C:\\Users\\yassi\\AppData\\Local\\Temp/ipykernel_14600/593265475.py:2: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  headers = np.genfromtxt(path, delimiter = ',', autostrip = True, dtype = np.str)[0].tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['apple', '10/19/2022', '10/25/2022', '4.1', '99'],\n",
       "       ['apple', '10/20/2022', '10/25/2022', '4.1', '67'],\n",
       "       ['apple', '10/21/2022', '10/25/2022', '4.1', '23'],\n",
       "       ['apple', '10/22/2022', '10/25/2022', '', ''],\n",
       "       ['apple', '10/23/2022', '10/25/2022', '5.1', '89'],\n",
       "       ['apple', '10/24/2022', '10/25/2022', '4.1', '98'],\n",
       "       ['apple', '10/25/2022', '10/25/2022', '3.1', '97'],\n",
       "       ['apple', '10/26/2022', '10/25/2022', '3.1', '44'],\n",
       "       ['apple', '10/27/2022', '10/25/2022', '2.1', '33'],\n",
       "       ['apple', '10/28/2022', '10/25/2022', '2.1', '89'],\n",
       "       ['apple', '10/29/2022', '10/25/2022', '1.1', '92'],\n",
       "       ['apple', '10/30/2022', '10/25/2022', '4.1', '91'],\n",
       "       ['orange', '10/19/2022', '10/23/2022', '', '100'],\n",
       "       ['orange', '10/20/2022', '10/23/2022', '3', '22'],\n",
       "       ['orange', '10/21/2022', '10/23/2022', '4', '22'],\n",
       "       ['orange', '10/22/2022', '10/23/2022', '2', '22'],\n",
       "       ['orange', '10/23/2022', '10/23/2022', '2', '22'],\n",
       "       ['orange', '10/24/2022', '10/23/2022', '2', '22'],\n",
       "       ['orange', '10/25/2022', '10/23/2022', '4', '22'],\n",
       "       ['orange', '10/26/2022', '10/23/2022', '5', '22'],\n",
       "       ['orange', '10/27/2022', '10/23/2022', '6', '22'],\n",
       "       ['orange', '10/28/2022', '10/23/2022', '7', '22'],\n",
       "       ['orange', '10/29/2022', '10/23/2022', '2', '45'],\n",
       "       ['orange', '10/30/2022', '10/23/2022', '6.1', '56']], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_KPIs= np.genfromtxt(path, delimiter = ',', skip_header = 1, autostrip = True, dtype = np.str)\n",
    "headers = np.genfromtxt(path, delimiter = ',', autostrip = True, dtype = np.str)[0].tolist()\n",
    "# sorting KPIs alphabetically to the granularity\n",
    "sorted_KPIs = raw_KPIs[np.lexsort((raw_KPIs[:,1],raw_KPIs[:,0]))]\n",
    "sorted_KPIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c123f0",
   "metadata": {},
   "source": [
    "# Date preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b132d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_days(day1,day2):\n",
    "    \"\"\"returns the difference between two dates in (days) unit \"\"\"\n",
    "    day1 = get_formatted_date(day1)\n",
    "    day2 = get_formatted_date(day2)\n",
    "\n",
    "    \n",
    "    delta = abs(day2 - day1)\n",
    "    return int(delta.days)\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    \"\"\"parse the string date and returns the date in the python conventional date format\"\"\"\n",
    "    date = dateutil.parser.parse(date_str)\n",
    "    return datetime(date.year, date.month, date.day)\n",
    "    \n",
    "x = '10/19/2022'\n",
    "y = \"2022-10-23\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92214d39",
   "metadata": {},
   "source": [
    "# Importing  KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06eb77b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['apple', 12, 0, 6], ['orange', 12, 12, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing cell_name, number_of_occurences, index_of_first_Occurence,index_of_activity_date --> \"cells_occurences\"\n",
    "cells_occurences = [[]]\n",
    "\"\"\" for cell in sorted_KPIs[:,0]:\n",
    "    count = np.count_nonzero(sorted_KPIs[:,0] == cell)\n",
    "    cells_occurences.append([cell, count, list(sorted_KPIs[:,0]).index(cell)])\"\"\"\n",
    "\n",
    "for i,cell in enumerate(sorted_KPIs[:,0:1]):\n",
    "    count = np.count_nonzero(sorted_KPIs[:,0] == cell[0])\n",
    "    index_of_first_Occurence = list(sorted_KPIs[:,0]).index(cell[0])\n",
    "    #index_of_event = list(sorted_KPIs[:,1].index())\n",
    "    cells_occurences.append([cell[0], count,index_of_first_Occurence ])  \n",
    "    \n",
    "# tupling the matrix to check for uniqueness\n",
    "new_array = [tuple(row) for row in cells_occurences]\n",
    "cells_occurences = np.unique(new_array)\n",
    "\n",
    "#De-tupling and removing the first empty entry\n",
    "cells_occurences = [list(item) for item in cells_occurences]\n",
    "cells_occurences = cells_occurences[1:][:]\n",
    "cells_occurences\n",
    "\n",
    "#add the number of days from the first provided KPI date for each cell until the activity date\n",
    "for i,cell in enumerate(cells_occurences):\n",
    "    \n",
    "    index = cell[2]\n",
    "    date1 = sorted_KPIs[index][1]\n",
    "    date2 = sorted_KPIs[index][2]\n",
    "    activity_span = (get_delta_days(date1,date2))\n",
    "    cells_occurences[i].append(activity_span)\n",
    "\n",
    "cells_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fe4b5",
   "metadata": {},
   "source": [
    "# Converting string data to numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437f3f2",
   "metadata": {},
   "source": [
    "Slicing the whole sorted KPIs by removing the Date and Cells after sorting them according to the date then cell.\n",
    "However, the Numpy and pandas can not cast string matrix to float, therefore, an iterative approach was used with \"pd.to_numeric\" and then retransforming the pd frame to the numpy array while preserving the order and avoiding the preprocessing again\n",
    "\n",
    "https://stackoverflow.com/questions/16223483/forced-conversion-of-non-numeric-numpy-arrays-with-nan-replacement\n",
    "https://stackoverflow.com/questions/68907033/how-to-convert-a-2d-array-of-strings-and-numbers-to-a-numpy-float-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e654f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.1,  99. ],\n",
       "       [  4.1,  67. ],\n",
       "       [  4.1,  23. ],\n",
       "       [  nan,   nan],\n",
       "       [  5.1,  89. ],\n",
       "       [  4.1,  98. ],\n",
       "       [  3.1,  97. ],\n",
       "       [  3.1,  44. ],\n",
       "       [  2.1,  33. ],\n",
       "       [  2.1,  89. ],\n",
       "       [  1.1,  92. ],\n",
       "       [  4.1,  91. ],\n",
       "       [  nan, 100. ],\n",
       "       [  3. ,  22. ],\n",
       "       [  4. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  4. ,  22. ],\n",
       "       [  5. ,  22. ],\n",
       "       [  6. ,  22. ],\n",
       "       [  7. ,  22. ],\n",
       "       [  2. ,  45. ],\n",
       "       [  6.1,  56. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numeric_KPIs = sorted_KPIs[1:,2:]\n",
    "numeric_KPIs = sorted_KPIs[:,3:]\n",
    "numeric_KPIs =  [pd.to_numeric(col, errors='coerce') for col in numeric_KPIs ] \n",
    "numeric_KPIs = np.asarray(numeric_KPIs)\n",
    "numeric_KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f88ba9",
   "metadata": {},
   "source": [
    "# Voting for Success Rate or Drop Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318a21cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recognize_data_optimality(data):\n",
    "    \"\"\" sums up the value in each column and if sum is above 40 then it is a success rate data, otherwise it is a drop rate\"\"\"\n",
    "    voters=[]\n",
    "    no_cols = len(data[0])\n",
    "    no_rows = len(data)\n",
    "    for j in range(no_cols):\n",
    "        negative_counter = 0\n",
    "        positive_counter = 0\n",
    "        \n",
    "        for i in range(no_rows):\n",
    "            if data[i][j] == \"nan\":\n",
    "                continue\n",
    "                \n",
    "            if data[i][j] > 30:\n",
    "                positive_counter +=1\n",
    "            else:\n",
    "                negative_counter +=1\n",
    "        # voter = 1 --> success rate\n",
    "        # voter = 0 --> drop rate\n",
    "        voter = 1 if positive_counter > negative_counter else 0\n",
    "        voters.append(voter)\n",
    "    return voters\n",
    "\n",
    "\n",
    "#  voter = 1 --> success rate / voter = 0 --> drop rate\n",
    "voters = recognize_data_optimality(numeric_KPIs)\n",
    "voters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869281b9",
   "metadata": {},
   "source": [
    "# Replacing the NANs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a659f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.1,  99. ],\n",
       "       [  4.1,  67. ],\n",
       "       [  4.1,  23. ],\n",
       "       [  0. , 100. ],\n",
       "       [  5.1,  89. ],\n",
       "       [  4.1,  98. ],\n",
       "       [  3.1,  97. ],\n",
       "       [  3.1,  44. ],\n",
       "       [  2.1,  33. ],\n",
       "       [  2.1,  89. ],\n",
       "       [  1.1,  92. ],\n",
       "       [  4.1,  91. ],\n",
       "       [  0. , 100. ],\n",
       "       [  3. ,  22. ],\n",
       "       [  4. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  2. ,  22. ],\n",
       "       [  4. ,  22. ],\n",
       "       [  5. ,  22. ],\n",
       "       [  6. ,  22. ],\n",
       "       [  7. ,  22. ],\n",
       "       [  2. ,  45. ],\n",
       "       [  6.1,  56. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the NAN values with 0 if it's drop rate and with 1 if it's success rate\n",
    "def replace_nan(data):\n",
    "    no_cols = len(data[0])\n",
    "    no_rows = len(data)\n",
    "    for j in range(no_cols):\n",
    "        if voters[j] == 1:\n",
    "            np.nan_to_num(data[:,j], copy=False, nan=100, posinf=100, neginf=0)\n",
    "        else:\n",
    "            np.nan_to_num(data[:,j], copy=False, nan=0, posinf=100, neginf=0)\n",
    "    \n",
    "replace_nan(numeric_KPIs)\n",
    "numeric_KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c006ae",
   "metadata": {},
   "source": [
    "# Outlier check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6af9bd",
   "metadata": {},
   "source": [
    "Return array where sudden peaks in data sequence is removed, to avoid deviating the mean significantly while considering which type of peaks should be removed (+ve) or (-ve) peaks by sorting the array ascendingly or descendingly and removing element by element while comparing the new avg with original avg and removing the element that caused big difference between the old and new avg. The function accounts of low samples number, where if the reduced array size is half of the original array,then the data is fluctuating heavily, and function will return original data \n",
    "https://math.stackexchange.com/questions/22348/how-to-add-and-subtract-values-from-an-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefddc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old: [1, 2, 3]\n",
      "new: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def outlier_check(old,KPI_type = 0,tolerance_rate =10, new_size_limit = 2 ):\n",
    "\n",
    "    old_avg = mean(old)\n",
    "    l = len(old)\n",
    "    if l < 5:\n",
    "        return old\n",
    "    \n",
    "    tolerance = tolerance_rate/100 * old_avg\n",
    "    \n",
    "    # new array returned after removing the outliers\n",
    "    modified = old.copy()\n",
    "    # counter of how many elements were removed from the orignial array\n",
    "    rmv_cnt =0\n",
    "    \n",
    "\n",
    "    \n",
    "    if KPI_type == 1:\n",
    "        # KPI_type = 1, means the KPI is success rate, and the function will remove the low values\n",
    "        new = sorted(old, reverse=False)\n",
    "        condition = lambda delta:delta < tolerance\n",
    "    else:\n",
    "        # KPI_type = 0, means the KPI is drop rate, and the function will remove the high values\n",
    "        new = sorted(old, reverse=True)\n",
    "        condition = lambda delta:delta > tolerance\n",
    "    \n",
    "    for num in new:\n",
    "        new_avg = old_avg - (num - old_avg)/l\n",
    "        if condition(abs(new_avg - old_avg)):\n",
    "            modified.remove(num)\n",
    "            rmv_cnt +=1\n",
    "            if rmv_cnt < int(l/new_size_limit):\n",
    "                # return the original array iff the removed elements count are more than half of the whole array elements count\n",
    "                return old\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    \n",
    "    \n",
    "    return modified\n",
    "d = [2,7,3,2,2,2,3,7]\n",
    "d2 = [2,3,2,3,2,3]\n",
    "d3 = [1,2,3]\n",
    "n = outlier_check(d3,KPI_type = 0,tolerance_rate =10, new_size_limit = 10)\n",
    "mean(n)\n",
    "print(\"old:\",d3)\n",
    "print(\"new:\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a041f27",
   "metadata": {},
   "source": [
    "# Improvement Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d023745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def benchmark(pre,post, KPI_type = 1):\n",
    "    pre_mean = mean(pre)\n",
    "    post_mean = mean(post)\n",
    "    if KPI_type == 1:\n",
    "        # Success rate KPIs\n",
    "        delta = post_mean - pre_mean\n",
    "    else:\n",
    "        # Drop rate KPIs\n",
    "        delta = -1 * (post_mean - pre_mean)\n",
    "        \n",
    "    return  100 * (delta / pre_mean)\n",
    "benchmark([1,2,3],[5,6,7],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8fdc0",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc11a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple KPI of 0 is : 28.86178861788618\n",
      "apple KPI of 1 is : -14.729493891797565\n",
      "orange KPI of 0 is : -108.4415584415584\n",
      "orange KPI of 1 is : -19.832826747720368\n"
     ]
    }
   ],
   "source": [
    "cells_benchmarked_KPIs=[]\n",
    "for i,cell in enumerate(cells_occurences):\n",
    "    \n",
    "    cell_name,length,start,mid = cell\n",
    "    benchmarked_KPIs = []\n",
    "    \n",
    "    for j in range(len(numeric_KPIs[0])):\n",
    "        \n",
    "        raw_pre_KPIs = numeric_KPIs[start:start+mid+1,j].tolist()\n",
    "        raw_post_KPIs = numeric_KPIs[start+mid+1:start+length,j].tolist()\n",
    "        \n",
    "        pre_KPIs = outlier_check(raw_pre_KPIs,KPI_type = voters[j],tolerance_rate =10, new_size_limit = 2)\n",
    "        post_KPIs = outlier_check(raw_post_KPIs,KPI_type = voters[j],tolerance_rate =10, new_size_limit = 2)\n",
    "        \n",
    "        benchmarked_KPI = benchmark(pre =pre_KPIs, post = post_KPIs, KPI_type = voters[j])\n",
    "        benchmarked_KPIs.append(round(benchmarked_KPI,1))\n",
    "        \n",
    "        print(f\"{cell_name} KPI of {voters[j]} is : {benchmarked_KPI}\")\n",
    "        \n",
    "    cells_benchmarked_KPIs.append(benchmarked_KPIs)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180409d",
   "metadata": {},
   "source": [
    "# Preparing the final benchmark Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f65bf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_benchmarks = [[headers[0]] + headers[3:]]\n",
    "for i in range(len(cells_occurences)):\n",
    "    # cell name + the benchmarked KPIs\n",
    "    data = [cells_occurences[i][0]] +cells_benchmarked_KPIs[i]\n",
    "    all_benchmarks.append(data)\n",
    "\n",
    "all_benchmarks[0].append(\"Status\")\n",
    "# Status check for each cell\n",
    "for cell in all_benchmarks[1:]:\n",
    "    if all(KPI > 0 for KPI in cell[1:]):\n",
    "        status = \"Improved\"\n",
    "    elif all(KPI == 0 for KPI in cell[1:]):\n",
    "        status = \"Stable\"\n",
    "    else:\n",
    "        status = \"Degraded\"\n",
    "    cell.append(status)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af2cc2",
   "metadata": {},
   "source": [
    "# Saving the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3ef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIs_df = pd.DataFrame(all_benchmarks)\n",
    "KPIs_df.to_csv(final_csv_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "636067b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cell', 'price', 'SR', 'Status'],\n",
       " ['apple', 28.9, -14.7, 'Degraded'],\n",
       " ['orange', -108.4, -19.8, 'Degraded']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
